This project is part of my PhD dissertation project.
This section follows from the first section dedicated to the Mathematical Modeling of our co-authorship network (available [HERE](http://#)).

The purpose of this section is the use of Exponential Random Graph Modeling (ERGM) as a  Statistical modeling to better understand and explain our malaria co-authorship network.
Loading the necessary packages...

```{r setup, include=FALSE,cache=FALSE}
setwd('~/R/R_scripts')
library(igraph)
library(ergm)
library(parallel)
library(doParallel)
library(lubridate)
library(snow)
library(methods)
library(dplyr)
library(stringr)
```

Loading the variables from the last section...

```{r var-load,cache=FALSE}
load('./Rdata/mnet.rda')
load('./Rdata/mnet2.rda')
load('./Rdata/mnet2.gc.rda')
load('./Rdata/auth_data.rda')
load('./Rdata/edges.rda')
load('./Rdata/mnet2.gc.rda')

mnet3 <- read_graph('./graphs/CAnet_graph.graphml', format = 'graphml')
mnet.w <- read_graph('./graphs/CAnet_weight.graphml', format = 'graphml')
```

Some data manipulations: Defining Local, Regional and International actors

```{r manip, cahce=FALSE}
newCountry<-V(mnet2)$country %>% str_replace("\n", "")
V(mnet2)$country<-newCountry
cont<-read.csv("continent.csv", header = T)
continent<-list()
ctnt<-as.vector(cont$Continent)
ctry<-as.vector(cont$Country)
for(i in 1:length(ctnt)){
  continent[[toupper(ctry[i])]]<-toupper(ctnt[i])
}
# V(mnet2)$continent<-numeric(length(V(mnet)$country))
newContinent<-c()
for(i in 1:length(V(mnet2)$country)){
  entry<-continent[[V(mnet2)$country[i]]]
  if(is.null(entry)){entry<-''}
  newContinent<-c(newContinent, entry)
}
V(mnet2)$continent<-newContinent

# Assigning collaboration scope
collabType<-c()
for(i in 1:length(V(mnet2)$continent)){
  collabScope=''
  if(V(mnet2)$country[i]=='BENIN' && V(mnet2)$continent[i]=='AFRICA'){
    collabScope<-'NATIONAL'
  } else if(V(mnet2)$country[i]!='BENIN' && V(mnet2)$continent[i]=='AFRICA'){
    collabScope<-'REGIONAL'
  } else if(V(mnet2)$continent[i]!='AFRICA' && V(mnet2)$continent[i]!='') {
    collabScope<-'INTERNATIONAL'
  } else{
    collabScope<-NA
  }
  collabType<-c(collabType,collabScope)
}
V(mnet2)$collabType<-collabType
```

Since this processing is going to take a lot of time, we decide to parallelize all the computations:

```{r detect-cores}
cores=detectCores() # get number of cores
# cl <- makeCluster(cores[1]-2) #I decide to run leave 2 cores out
# registerDoParallel(cl)
```



```{r preproc,cache=FALSE}
A <- get.adjacency(mnet3)
v.attrs <- get.data.frame(mnet3, what="vertices")
v.attrs$name <- V(mnet.w)$name
v.attrs$timesCited <- V(mnet.w)$timesCited
v.attrs$numPub <- V(mnet.w)$numPub
v.attrs$community <- V(mnet2)$community
v.attrs$degree <- V(mnet2)$degree
v.attrs$affiliation <- V(mnet.w)$place
v.attrs$city <- V(mnet.w)$affil
v.attrs$country <- V(mnet.w)$country
v.attrs$collabType <- V(mnet2)$collabType


mnet3.simple <- network::as.network(as.matrix(A), directed=FALSE)
network::set.vertex.attribute(mnet3.simple, "timesCited", V(mnet.w)$timesCited)
network::set.vertex.attribute(mnet3.simple, "numPub", V(mnet.w)$numPub)
network::set.vertex.attribute(mnet3.simple, "community", V(mnet2)$community)
network::set.vertex.attribute(mnet3.simple, "degree", V(mnet2)$degree)
network::set.vertex.attribute(mnet3.simple, "collabType", V(mnet2)$collabType)

# pairCited <- get.adjacency(mnet2,attr = 'timesCited')
# nCollab <- as_adjacency_matrix(mnet2,attr = 'weight')
# 
# # Adding edge attributes
# mnet3.simple %e% 'pairCited' <- A
# mnet3.simple %e% 'nCollab' <- nCollab
mnet3.simple
```



```{r formula1}
mod1.f <- formula(mnet3.simple ~ edges)
mod1.f
mnet3.simple ~ edges
summary.statistics(mod1.f)
```



```{r model-fitting1,cache=FALSE}
t0 <- Sys.time()
mod1 <- ergm(mod1.f, iterations=1000, 
                         control=control.ergm(parallel=cores, parallel.type="PSOCK", MCMC.samplesize=1000,
                                              MCMC.interval=500, MCMLE.maxit = 1000, MCMC.burnin = 20000, seed=25))
Sys.time() - t0
# save(my.ergm.bern.fit, file = './Rdata/my.ergm.bern.fit.rda')
```



```{r model-summary,cache=FALSE}
anova.ergm(mod1)
summary(mod1)
```



```{r save-mod1,cache=FALSE}
save(mod1, file = 'modData/mod1.rda')
```

The coefficient of this model is 
`r mod1$coef`
 and the model likelihood is 
`r mod1$mle.lik`
The coefficient estimate tell us that if this network had been generated by 
the posited model, then the probability corresponding to the log-odds of a tie should is 
`r plogis(mod1$coef)`
. This probability also represents the
fraction of possible edges that are realized. The amount of deviance explained by the model
is represented by two standard measures of model fit based on the likelihood (AIC and BIC),
and the MCMC standard error. Since this model exhibits dyadic independence,
MCMC estimation is not necessary, and the MCMC standard error does not apply.
From our section on the mathematical modeling of our network, we know that our network is not random.
To explore alternative hypotheses about the structure that exists and the underlying processes 
that generated our network, we rely on the strength of ERGM to model building.

From previous analyses, we have shown that prolific authors in our network tend to collaborate more.
We have also demonstrated a tendency towards collaboration within authors of the same clusters/communities.

Therefore, a good model to begin with will be a model that proposes assortative mixing i.e a greater
probability of authors collaborating with other authors of the same productivity 
(number of publications, number of times cited, or research cluster/community). Furthermore, this model
is convenient in that it exhibits dyadic independence. [Hunter et al. (2008b)].
We assume a uniform tendency towards assortative mixing within each attribute class 
(same tendency to collaborate for within cluster/community)
We fit the model using the nodecov term (main effect of a continuous covariate), and the nodematch term
(uniform homophily) for our categorical variable "community".

```{r formula2,cache=FALSE}
mod2.f <- formula(mnet3.simple ~ edges + nodecov("timesCited") + nodecov('degree') +
                        nodecov("numPub") + nodematch("community") + nodematch("collabType"))
summary.statistics(mod2.f)
```



```{r model-fitting2,cache=FALSE}
t0 <- Sys.time()
mod2 <- ergm(mod2.f, iterations=1000,
                       control=control.ergm(parallel=cores, parallel.type="PSOCK", MCMC.samplesize=1000,
                                            MCMC.interval=5000, MCMC.burnin = 20000, seed=25, MCMLE.maxit = 1000))
# save(mod1, file = './Rdata/mod1.rda')
Sys.time() - t0
summary(mod2)
anova.ergm(mod2)
```



```{r save-mod2,cache=FALSE}
save(mod2, file = 'modData/mod2.rda')
```

The new model converges after `r mod2$iterations` iterations. We can see that all 4 terms are significant with a dramatic 
improvement in model likelihood. Model likelihood = `r mod2$mle.lik`

The log-odds of a collaboration that is completely heterogeneous is `r round(mod2$coef[1],2)`, hence the completely heterogeneous probability of a two authors collaborating is `r plogis(mod2$coef[1])`. The log-odds of a collaboration homogeneous between by communities is `r round(mod2$coef[4],2)`, the homogeneous probability of two authors collaborating between the same community is `r plogis(mod2$coef[5])`, and the homogeneous probability of two authors with the same collaboration type collaborating is 
`r plogis(mod2$coef[6])`.
The log-odds of a collaboration that is homogeneous in all 5 attributes is `r sum(mod2$coef)` and the associated probability is `r plogis(sum(mod2$coef))`

All the probabilities for each attribute are: `r plogis(mod2$coef)`

Often times, it is typical to include the nodefactor term to capture interaction or second order effects of attributes.

Let's run another model with this new term:

```{r formula3,cache=FALSE}
modd3.f <- formula(mnet3.simple ~ edges + nodecov("timesCited") + nodecov('degree') + nodecov("numPub") + nodematch("community") + nodematch("collabType") + nodefactor("collabType"))
summary.statistics(mod3.f)
```



```{r model-fitting3,cache=FALSE}
t0 <- Sys.time()
modd3 <- ergm(modd3.f, iterations=1000,
                       control=control.ergm(parallel=cores, parallel.type="PSOCK", MCMC.samplesize=1000,
                                            MCMC.interval=5000, MCMC.burnin = 20000, seed=25, MCMLE.maxit = 1000))
#save(mod2, file = './Rdata/mod2.rda')
Sys.time() - t0
summary(modd3)
anova.ergm(modd3)
```



```{r save-mod3,cache=FALSE}
save(modd3, file = 'modData/modd3.rda')
```

The new model converges after `r modd3$iterations` iterations. We can see that all terms are significant a model likelihood of 
`r modd3$mle.lik`.

Let's see what this model does and does not capture about the structure in our original data. To do this, we use the model fit that we have just generated to simulate new networks at random, and consider how these are similar to or different from our data.

```{r simulation1,cache=FALSE}
sim1 <- simulate(modd3, 
                 # burnin = 1e+6, # we may set the number of steps in the simulation chain to 1e+06
                 verbose = TRUE, seed = 25)
```



```{r save-simulation1,cache=FALSE}
save(sim1, file = 'modData/sim1.rda')
```

Let's examine the mixing matrix for the attribute collabType

```{r mixing-matrix1,cache=FALSE}
library(caret)
M1 <- mixingmatrix(sim1, "collabType")
confusionMatrix(M1$matrix)
```

Let's examine the mixing matrix for the attribute community

```{r mixing-matrix1b,cache=FALSE}
M2 <- mixingmatrix(sim1, "community")
confusionMatrix(M2$matrix)
```

This model captures more the research community with an accuracy of 92.57%. It performed less with the collaboration type with an accuracy of 55,82%.

*Identifying Model degeneracy*
We first fit a triangle model

```{r degeneracy-checking,cache=FALSE}
mod4.f <- formula(mnet3.simple ~ edges + triangle)
t0 <- Sys.time()
mod4 <- ergm(mod4.f, maxit=1000, verbose = TRUE,
             control = control.ergm(MCMLE.maxit=1000, MCMC.samplesize = 10000, MCMC.interval = 1000, seed=25))
Sys.time() - t0
summary(mod4)
anova.ergm(mod4)
```

```{r save-mod4,cache=FALSE}
save(mod4, file = 'modData/mod4.rda')
```



```{r mod4-mcmc_diag,cache=FALSE}
mcmc.mod4 <- mcmc.diagnostics(mod4)
mcmc.mod4
save(mcmc.mod4, file = "modData/mcmc-mod4.rda")
```



```{r mod4-mcmc_diag_save}
pdf("./figure2/mod4diagnostics.pdf")
mcmc.diagnostics(mod4)
dev.off()
```

We now fit model 3 with the triangle ergm term

```{r formula5,cache=FALSE}
mod5.f <- formula(mnet3.simple ~ edges + triangle + nodecov("timesCited") + nodecov('degree') +
                         nodecov("numPub") + nodematch("community") + nodematch("collabType") + nodefactor("collabType"))
summary.statistics(mnet3.ergm2)
```



```{r model-fitting5,cache=FALSE}
t0 <- Sys.time()
mod5 <- ergm(mod5.f, iterations=1000,
             control=control.ergm(parallel=cores, parallel.type="PSOCK", MCMC.samplesize=1000,
                                  MCMC.interval=5000, MCMC.burnin = 20000, seed=25, MCMLE.maxit = 1000))
#save(mod2, file = './Rdata/mod2.rda')
Sys.time() - t0
summary(mod5)
anova.ergm(mod5)
```



```{r mod5-mcmc_diag,cache=FALSE}
mcmc.mod5 <- mcmc.diagnostics(mod5)
mcmc.mod5
save(mcmc.mod5, file = "modData/mcmc-mod5.rda")
```

```{r mod5-mcmc_diag_save}
pdf("./figure2/mod5diagnostics.pdf")
mcmc.diagnostics(mod5)
dev.off()
```



```{r save-mod5,cache=FALSE}
save(mod5, file = 'modData/mod5.rda')
```

The new model, model 5 converges after `r mod3$iterations` iterations. We can see that all terms are significant a model likelihood of 
`r mod3$mle.lik`.

Let's see what this model does and does not capture about the structure in our original data. To do this, we use the model fit that we have just generated to simulate new networks at random, and consider how these are similar to or different from our data.

```{r simulation2,cache=FALSE}
sim2 <- simulate(mod5, 
                 # burnin = 1e+6, # we may set the number of steps in the simulation chain to 1e+06
                 verbose = TRUE, seed = 25)
```

```{r save-simulation2,cache=FALSE}
save(sim2, file = 'modData/sim2.rda')
```


Let's examine the mixing matrix for the attribute collabType

```{r mixing-matrix2,cache=FALSE}
M3 <- mixingmatrix(sim2, "collabType")
confusionMatrix(M3$matrix)
```


Let's examine the mixing matrix for the attribute community

```{r mixing-matrix2b,cache=FALSE}
M4 <- mixingmatrix(sim3, "community")
confusionMatrix(M4$matrix)
```

*Non-degenerate dyadic dependence models*

We explore clustering using GWESP (geometrically weighted edgewise shared partner) statistic, one of the more recently proposed statistics that is closely related to the triangle (Snijders et al. (2006); Robins, Snijders, Wang, Handcock, and Pattison (2007b) or Hunter (2007)). 
The lower the value of the scaling parameter of GWESP, the less likely the model is to be degenerate.

```{r non-degenerate,cache=FALSE}
mod6.f <- formula(mnet3.simple ~ edges + gwesp(0, fixed = TRUE) + nodecov("timesCited") 
                  + nodecov('degree') + nodecov("numPub") + nodematch("community") 
                  + nodematch("collabType") + nodefactor("collabType"))
t0 <- Sys.time()
mod6 <- ergm(mod6.f, verbose = TRUE, control = control.ergm(MCMLE.maxit=1000, MCMC.samplesize = 10000,
                                                            MCMC.interval = 10000, seed=25))
Sys.time() - t0
summary(mod6)
anova.ergm(mod6)
```


```{r save-mod6,cache=FALSE}
save(mod6, file = 'modData/mod6.rda')
```


```{r mod6-mcmc_diag,cache=FALSE}
mcmc.mod6 <- mcmc.diagnostics(mod6)
mcmc.mod6
save(mcmc.mod6, file = "modData/mcmc-mod6.rda")
```


```{r mod6-mcmc_diag_save,cache=FALSE}
pdf("./figure2/mod6diagnostics.pdf")
mcmc.diagnostics(mod6)
dev.off()
```


Now let's see if model 6 does a better job than model 4

```{r mod6-sim,cache=FALSE}
sim3 <- simulate(mod6, nsim = 100,
                 # burnin = 1e+6, # we may set the number of steps in the simulation chain to 1e+06
                 verbose = TRUE, seed = 25)
```


```{r save-simulation3,cache=FALSE}
save(sim3, file = 'modData/sim3.rda')
```


Let's assess how does the distribution of triangles in mod4 compare to the original network:

```{r mod6-comp,cache=FALSE}
mod6.tridist <- sapply(sim2$networks, function(x) summary(x ~ triangle))
hist(mod6.tridist)
mnet3.tri <- summary(mnet3.simple ~ triangle)
arrows(mnet3.tri, 20, mnet3.tri, 5, col = "red", lwd = 3)
sum(fmh.tri <= model6.tridist)
```

```{r mod4-deg,cache=FALSE}
gof6.deg <- gof(mod6 ~ degree, verbose = TRUE)
plot(gof6.deg)
```

# ```{r gof4,cache=FALSE}
# # gof4.deg
# ```



```{r gof6-deg,cache=FALSE}
pdf("./figure2/gof6-deg.pdf")
plot(gof6.deg)
dev.off()
```

Let us now compare our model fit to our data on degree distribution

```{r diag-mod6,cache=FALSE}
t0 <- Sys.time()
diag.mod6 <- gof(mod6, control=control.gof.ergm(parallel=cores, parallel.type="PSOCK"))
Sys.time() - t0
jpeg(filename = './figure2/diag.mod6.jpg')
plot(diag.mod6)
dev.off()
mcmc.diagnostics(mod6)
```



```{r save-diag-mod6,cache=FALSE}
save(diag.mod6, file = "modData/diag.mod6.rda")
#save(diag, file = './Rdata/diag.my.ergm.bern.fit.rda')
```



```{r viz-diag, fig.width=20,fig.height=40}
par(mfrow=c(2, 2))
plot(diag)
```

