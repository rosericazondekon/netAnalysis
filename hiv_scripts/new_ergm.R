#' This project is part of my PhD dissertation project.
#' This section follows from the first section dedicated to the Mathematical Modeling of our co-authorship network (available [HERE](http://#)).
#'
#' The purpose of this section is the use of Exponential Random Graph Modeling (ERGM) as a  Statistical modeling to better understand and explain our malaria co-authorship network.
#' Loading the necessary packages...

#+ setup, include=FALSE,cache=FALSE
setwd('~/R/R_scripts')
library(igraph)
library(ergm)
library(parallel)
library(doParallel)
library(lubridate)
#/* library(Rmpi) */
library(snow)
library(methods)

#' Loading the variables from the last section...

#+ var-load,cache=FALSE
load('./Rdata/mnet.rda')
load('./Rdata/mnet2.rda')
load('./Rdata/mnet2.gc.rda')
load('./Rdata/auth_data.rda')
load('./Rdata/edges.rda')
load('./Rdata/mnet2.gc.rda')

# /* Loading a simplified version of the network */
mnet3 <- read_graph('./graphs/CAnet_graph.graphml', format = 'graphml')
mnet.w <- read_graph('./graphs/CAnet_weight.graphml', format = 'graphml')

#' Since this processing is going to take a lot of time, we decide to parallelize all the computations:
#+ detect-cores
# /* create a cluster with fixed number of processes */
cores=detectCores() # get number of cores
# cl <- makeCluster(cores[1]-2) #I decide to run leave 2 cores out
# registerDoParallel(cl)

#+ preproc,cache=FALSE
A <- get.adjacency(mnet3)
v.attrs <- get.data.frame(mnet3, what="vertices")
v.attrs$name <- V(mnet.w)$name
v.attrs$timesCited <- V(mnet.w)$timesCited
v.attrs$numPub <- V(mnet.w)$numPub
v.attrs$community <- V(mnet2)$community
v.attrs$degree <- V(mnet2)$degree
v.attrs$affiliation <- V(mnet.w)$place
v.attrs$city <- V(mnet.w)$affil
v.attrs$country <- V(mnet.w)$country

# Setting node attributes...
mnet3.simple <- network::as.network(as.matrix(A), directed=FALSE)
network::set.vertex.attribute(mnet3.simple, "timesCited", V(mnet.w)$timesCited)
network::set.vertex.attribute(mnet3.simple, "numPub", V(mnet.w)$numPub)
network::set.vertex.attribute(mnet3.simple, "community", V(mnet2)$community)
network::set.vertex.attribute(mnet3.simple, "degree", V(mnet2)$degree)

# Setting edge attributes
network::set.edge.attribute(mnet3.simple, "year", E(mnet.w)$year)
network::set.edge.attribute(mnet3.simple, "EdgeCited", E(mnet.w)$timesCited)
network::set.edge.attribute(mnet3.simple, "numPub", E(mnet.w)$numPub)

# Looking at the network...
mnet3.simple

#' We start by fitting the simplest model which is also the Erdos-Renyi Random graph model a.k.a the Bernoulli model
#+ mod0.f
mod0.f <- formula(mnet3.simple ~ edges)
mod0.f

# Summary...
summary.statistics(mod0.f)

#' We refer to this model as model zero
#+ mod0,cache=TRUE
t0 <- Sys.time()
mod0 <- ergm(mod0.f, iterations=1000, 
                         control=control.ergm(parallel=cores, parallel.type="PSOCK", MCMC.samplesize=1000,
                                              MCMC.interval=500, MCMLE.maxit = 1000, MCMC.burnin = 20000, seed=25))
Sys.time() - t0
save(mod0, file = './Rdata/mod0.rda')

#' Let's look at the results...
#+ mod0-summary,cache=TRUE
anova.ergm(mod0)
summary(mod0)


#' The coefficient of this model is 
{{mod0$coef}}
#'  and the model likelihood is mod0$mle.lik =
{{mod0$mle.lik}}
#' The coefficient estimate tell us that if this network had been generated by 
#' the posited model, then the probability corresponding to the log-odds of a tie should is plogis(coef(mod0)[['edges']]) =
{{plogis(coef(mod0)[['edges']])}}
#' . This probability also represents the
#' fraction of possible edges that are realized and is the same as the probability of two researchers collaborating from our 
#' previous tutorials. The amount of deviance explained by the model
#' is represented by two standard measures of model fit based on the likelihood (AIC and BIC),
#' and the MCMC standard error. Since this model exhibits dyadic independence,
#' MCMC estimation is not necessary, and the MCMC standard error does not apply.

#' From our section on the mathematical modeling of our network, we know that our network is not random.
#' To explore alternative hypotheses about the structure that exists and the underlying processes 
#' that generated our network, we rely on the strength of ERGM to model building.
#' 
#' From previous analyses, we have shown that prolific authors in our network tend to collaborate more.
#' We have also demonstrated a tendency towards collaboration within authors of the same clusters/communities.
#' 
#' Therefore, a good model to begin with will be a model that proposes assortative mixing i.e a greater
#' probability of authors collaborating with other authors of the same productivity 
#' (number of publications, number of times cited, or research cluster/community). Furthermore, this model
#' is convenient in that it exhibits dyadic independence. [Hunter et al. (2008b)].
#' We assume a uniform tendency towards assortative mixing within each attribute class 
#' (same tendency to collaborate for within cluster/community)
#' We fit the model using the nodecov term (main effect of a continuous covariate), and the nodematch term
#' (uniform homophily) for our categorical variable "community".

#+ mod1.f
mod1.f <- formula(mnet3.simple ~ edges + nodecov("timesCited") + nodecov('degree') + 
                    nodecov("numPub") + nodematch("community"))
mod1.f

# Summary...
summary.statistics(mod1.f)

#' We refer to this model as model one
#+ mod1,cache=TRUE
t0 <- Sys.time()
mod1 <- ergm(mod1.f, iterations=1000, 
             control=control.ergm(parallel=cores, parallel.type="PSOCK", MCMC.samplesize=1000,
                                  MCMC.interval=500, MCMLE.maxit = 1000, MCMC.burnin = 20000, seed=25))
Sys.time() - t0
save(mod1, file = './Rdata/mod1.rda')

#' Let's look at the results...
#+ mod0-summary,cache=TRUE
anova.ergm(mod1)
summary(mod1)

#' The new model converges after 
{{mod1$mle.iterations}}
#' iterations. We can see that all 5 terms are significant with a dramatic 
#' improvement in model likelihood. Model likelihood = 
{{mod1$mle.lik}}
#' 
#' The log-odds of a collaboration that is completely heterogeneous is mod1$coef[1] =
{{round(mod1$coef[1],2)}}
#' , hence the completely heterogeneous probability of a two authors collaborating is plogis(coef(mod1)[['edges']]) =
{{plogis(coef(mod1)[['edges']])}}
#' 
#' . The log-odds of a collaboration homogeneous between communities is mod1$coef[5] =
{{round(mod1$coef[4],2)}}
#'  and the homogeneous probability of two authors collaborating between the same community is plogis(coef(mod1)[['nodematch.community']]) =
{{plogis(coef(mod1)[['nodematch.community']])}}
#' .
#' The log-odds of a collaboration that is homogeneous in all 5 attributes is sum(mod1$coef) =
{{sum(mod1$coef)}}
#'  and the associated probability is plogis(sum(mod1$coef)) =
{{plogis(sum(mod1$coef))}}
#' 

#' Let's assess how this model fits to our observed network data
#+ mod1-gof,cache=TRUE
t0 <- Sys.time()
diag.mod1 <- gof(mod1, control=control.gof.ergm(parallel=cores, parallel.type="PSOCK"))
Sys.time() - t0

#' Assessing Goodness-Of-Fit
#+ mod1-gof-results
diag.mod1
par(mfrow=c(2,2))
plot(diag.mod1)

#' As we can see from the "Goodness-of-fit for model statistics" table,
#' the model sdoe not seem to fit well the observed network although the dramatic improvement in the AIC and BIC.
#' 
#' The model statistics plot confirms our observation. To remedy this situation and often times, 
#' it is typical to include the nodefactor term to capture interaction or second order effects of attributes.
#' 
#' Let's run model 2 adding the nodefactor term to the mod2.fmodel:

#+ mod1.f

# Summary...
summary.statistics(mod2.f)

#' We refer to this model as model one
#+ mod1,cache=TRUE
t0 <- Sys.time()
mod2 <- ergm(mod2.f, iterations=1000, 
             control=control.ergm(parallel=cores, parallel.type="PSOCK", MCMC.samplesize=1000,
                                  MCMC.interval=500, MCMLE.maxit = 1000, MCMC.burnin = 20000, seed=25))
Sys.time() - t0
save(mod2, file = './Rdata/mod2.rda')

#' Let's look at the results...
#+ mod2-summary,cache=TRUE
anova.ergm(mod2)
summary(mod2)


#' The new model converges after mod2$mle.iterations =
{{mod2$mle.iterations}}
#'  iterations. We can see that all terms are significant with a 
#' model likelihood of 
{{mod2$mle.lik}}
#' . In addition
#' Let's see what this model does and does not capture about the structure in our original data.
#' To do this, we use the model fit that we have just generated to simulate new networks at random,
#' and consider how these are similar to or different from our data